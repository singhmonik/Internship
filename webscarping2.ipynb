{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "257f1158",
   "metadata": {},
   "source": [
    "# question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce92b4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.4.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.21.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1145560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cddd8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "131175a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8d3ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,'suggestor-input')\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3590ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "location.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2302e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cb91d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "706de8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title for the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scarping job location for the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scarping company name for the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# scraping experience required for given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8726b6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title), len(job_location), len(company_name), len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac772cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contractual Hiring For Top MNC || Business Dat...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - CRM Platform</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HCL hiring For Data Analyst</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Customer Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Global Indian School Education Services</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Ahmedaba...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Assistant Manager/Manager - Data Analyst - Ana...</td>\n",
       "      <td>Delhi / NCR, Bangalore/Bengaluru</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Python Data Analyst - WFH</td>\n",
       "      <td>Remote</td>\n",
       "      <td>hCapital Business Consulting Private Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst - Decision Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Jana Small Finance Bank</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0  Contractual Hiring For Top MNC || Business Dat...   \n",
       "1                                Senior Data Analyst   \n",
       "2                        Data Analyst - CRM Platform   \n",
       "3                        HCL hiring For Data Analyst   \n",
       "4                              Customer Data Analyst   \n",
       "5                                   Sr. Data Analyst   \n",
       "6                             Data Analyst - FinTech   \n",
       "7  Assistant Manager/Manager - Data Analyst - Ana...   \n",
       "8                          Python Data Analyst - WFH   \n",
       "9                    Data Analyst - Decision Science   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2  Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...   \n",
       "3                 Pune, Chennai, Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                          Pune, Bangalore/Bengaluru   \n",
       "6  Mumbai, Hyderabad/Secunderabad, Pune, Ahmedaba...   \n",
       "7                   Delhi / NCR, Bangalore/Bengaluru   \n",
       "8                                             Remote   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                   Company_name Exp_required  \n",
       "0                                     TeamLease      5-8 Yrs  \n",
       "1                                         Optum     5-10 Yrs  \n",
       "2                             Artech infosystem      1-6 Yrs  \n",
       "3                              HCL Technologies      3-8 Yrs  \n",
       "4                                        Oracle      1-3 Yrs  \n",
       "5       Global Indian School Education Services     6-11 Yrs  \n",
       "6                                  Primo Hiring      1-2 Yrs  \n",
       "7                     Huquo Consulting Pvt. Ltd     6-11 Yrs  \n",
       "8  hCapital Business Consulting Private Limited      4-9 Yrs  \n",
       "9                       Jana Small Finance Bank      3-8 Yrs  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from above data\n",
    "df=pd.DataFrame({'Job_title':job_title, 'Job_location':job_location, 'Company_name':company_name, 'Exp_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782d33a7",
   "metadata": {},
   "source": [
    "# question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b67cc032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "274a4ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3df5022",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5384829",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,'suggestor-input')\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb78b0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "location.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63d6a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f6bf059",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfeb4da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scarping job location for the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scarping company name for the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a7276e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title), len(job_location), len(company_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5ac9a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job Opportunity on Data Science_ Python with T...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Chennai...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Mumbai, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>CitiusTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist/AIML Engineer</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...</td>\n",
       "      <td>upGrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACN - Applied Intelligence - C4DI - Sustainabi...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring Data Science Intern - DataTrained Educa...</td>\n",
       "      <td>Noida, Kolkata, Hyderabad/Secunderabad, Pune, ...</td>\n",
       "      <td>DataTrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tcs Hiring For Data Scientist</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - II</td>\n",
       "      <td>India, Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>SMARTPADDLE TECHNOLOGY PVT. LTD.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0  Job Opportunity on Data Science_ Python with T...   \n",
       "1                   Assistant Manager - Data Science   \n",
       "2                   Analystics & Modeling Specialist   \n",
       "3  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "4                       Data Scientist/AIML Engineer   \n",
       "5  ACN - Applied Intelligence - C4DI - Sustainabi...   \n",
       "6  Hiring Data Science Intern - DataTrained Educa...   \n",
       "7                                  Lead ML Scientist   \n",
       "8                      Tcs Hiring For Data Scientist   \n",
       "9                                Data Scientist - II   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0  Kolkata, Hyderabad/Secunderabad, Pune, Chennai...   \n",
       "1                  Mumbai, Pune, Bangalore/Bengaluru   \n",
       "2  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "3  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...   \n",
       "4  Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6  Noida, Kolkata, Hyderabad/Secunderabad, Pune, ...   \n",
       "7                        Mumbai, Bangalore/Bengaluru   \n",
       "8   Chennai, Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "9     India, Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "\n",
       "                                  Company_name  \n",
       "0                                Tech Mahindra  \n",
       "1                                   CitiusTech  \n",
       "2                                    Accenture  \n",
       "3  NTT DATA Business Solutions Private Limited  \n",
       "4                                       upGrad  \n",
       "5                                    Accenture  \n",
       "6                                  DataTrained  \n",
       "7                            Fractal Analytics  \n",
       "8              TATA CONSULTANCY SERVICES (TCS)  \n",
       "9             SMARTPADDLE TECHNOLOGY PVT. LTD.  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from above data\n",
    "df=pd.DataFrame({'Job_title':job_title, 'Job_location':job_location, 'Company_name':company_name})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b43e80",
   "metadata": {},
   "source": [
    "# question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "162a664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da7ac523",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46d2d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,'suggestor-input')\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a51228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "location.send_keys('Delhi/NCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2307348",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b07a310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "021b9b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scrape job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scrape the company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scarpe the experience required from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "187a52f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 ['4-9 Yrs', '6-8 Yrs', '4-9 Yrs', '0-2 Yrs', '8-10 Yrs', '3-8 Yrs', '6-10 Yrs', '5-8 Yrs', '1-2 Yrs', '3-8 Yrs']\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title), len(job_location), len(company_name), (experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00cc186a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job Opportunity on Data Science_ Python with T...</td>\n",
       "      <td>Delhi / NCR, Kolkata, Hyderabad/Secunderabad, ...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring Data Science Intern - DataTrained Educa...</td>\n",
       "      <td>Delhi / NCR, Noida, Kolkata, Hyderabad/Secunde...</td>\n",
       "      <td>DataTrained</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Nagpur, Bangalore/Bengaluru</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AVAP Agile Information Systems - Data Scientis...</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>AVAP Agile</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist Lead</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Cloudjune</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, New Delhi, Pune, Gurgaon/Gurugram...</td>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Bangalore/Bengaluru\\n(WFH during Covid)</td>\n",
       "      <td>Paytm</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Forecasting Analyst/ Data Scientist (US Client)</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru\\n(WFH du...</td>\n",
       "      <td>Concentrix</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0  Job Opportunity on Data Science_ Python with T...   \n",
       "1                   Analystics & Modeling Specialist   \n",
       "2  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "3  Hiring Data Science Intern - DataTrained Educa...   \n",
       "4                                     Data Scientist   \n",
       "5  AVAP Agile Information Systems - Data Scientis...   \n",
       "6                                Data Scientist Lead   \n",
       "7                                     Data Scientist   \n",
       "8                                     Data Scientist   \n",
       "9    Forecasting Analyst/ Data Scientist (US Client)   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0  Delhi / NCR, Kolkata, Hyderabad/Secunderabad, ...   \n",
       "1  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "2  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...   \n",
       "3  Delhi / NCR, Noida, Kolkata, Hyderabad/Secunde...   \n",
       "4                 Noida, Nagpur, Bangalore/Bengaluru   \n",
       "5  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "6  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "7  Delhi / NCR, New Delhi, Pune, Gurgaon/Gurugram...   \n",
       "8     Noida, Bangalore/Bengaluru\\n(WFH during Covid)   \n",
       "9  Gurgaon/Gurugram, Bangalore/Bengaluru\\n(WFH du...   \n",
       "\n",
       "                                  Company_name Experience_required  \n",
       "0                                Tech Mahindra             4-9 Yrs  \n",
       "1                                    Accenture             6-8 Yrs  \n",
       "2  NTT DATA Business Solutions Private Limited             4-9 Yrs  \n",
       "3                                  DataTrained             0-2 Yrs  \n",
       "4                                  GlobalLogic            8-10 Yrs  \n",
       "5                                   AVAP Agile             3-8 Yrs  \n",
       "6                                    Cloudjune            6-10 Yrs  \n",
       "7                                ZS Associates             5-8 Yrs  \n",
       "8                                        Paytm             1-2 Yrs  \n",
       "9                                   Concentrix             3-8 Yrs  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Job_title':job_title, 'Job_location':job_location, 'Company_name':company_name, 'Experience_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698a5ec9",
   "metadata": {},
   "source": [
    "# question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d69b1dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abad21c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.flipkart.com/\" \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbecd0dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementClickInterceptedException",
     "evalue": "Message: element click intercepted: Element <button class=\"L0Z3Pu\" type=\"submit\">...</button> is not clickable at point (556, 28). Other element would receive the click: <div class=\"_36HLxm col col-3-5\">...</div>\n  (Session info: chrome=105.0.5195.102)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x0131DF13+2219795]\n\tOrdinal0 [0x012B2841+1779777]\n\tOrdinal0 [0x011C423D+803389]\n\tOrdinal0 [0x011F99D4+1022420]\n\tOrdinal0 [0x011F78C4+1013956]\n\tOrdinal0 [0x011F54AB+1004715]\n\tOrdinal0 [0x011F4117+999703]\n\tOrdinal0 [0x011E9B76+957302]\n\tOrdinal0 [0x0120E7FC+1107964]\n\tOrdinal0 [0x011E94B4+955572]\n\tOrdinal0 [0x0120EA14+1108500]\n\tOrdinal0 [0x0121F192+1175954]\n\tOrdinal0 [0x0120E616+1107478]\n\tOrdinal0 [0x011E7F89+950153]\n\tOrdinal0 [0x011E8F56+954198]\n\tGetHandleVerifier [0x01612CB2+3040210]\n\tGetHandleVerifier [0x01602BB4+2974420]\n\tGetHandleVerifier [0x013B6A0A+565546]\n\tGetHandleVerifier [0x013B5680+560544]\n\tOrdinal0 [0x012B9A5C+1808988]\n\tOrdinal0 [0x012BE3A8+1827752]\n\tOrdinal0 [0x012BE495+1827989]\n\tOrdinal0 [0x012C80A4+1867940]\n\tBaseThreadInitThunk [0x75810419+25]\n\tRtlGetAppContainerNamedObjectPath [0x77E974ED+237]\n\tRtlGetAppContainerNamedObjectPath [0x77E974BD+189]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m          Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#locating the button and clicking it toh search for sunglasses\u001b[39;00m\n\u001b[0;32m      7\u001b[0m button\u001b[38;5;241m=\u001b[39mdriver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCLASS_NAME,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL0Z3Pu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mbutton\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:88\u001b[0m, in \u001b[0;36mWebElement.click\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclick\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;124;03m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLICK_ELEMENT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:396\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    394\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    395\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:428\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    426\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 428\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[0;32m    430\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:243\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m: Message: element click intercepted: Element <button class=\"L0Z3Pu\" type=\"submit\">...</button> is not clickable at point (556, 28). Other element would receive the click: <div class=\"_36HLxm col col-3-5\">...</div>\n  (Session info: chrome=105.0.5195.102)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x0131DF13+2219795]\n\tOrdinal0 [0x012B2841+1779777]\n\tOrdinal0 [0x011C423D+803389]\n\tOrdinal0 [0x011F99D4+1022420]\n\tOrdinal0 [0x011F78C4+1013956]\n\tOrdinal0 [0x011F54AB+1004715]\n\tOrdinal0 [0x011F4117+999703]\n\tOrdinal0 [0x011E9B76+957302]\n\tOrdinal0 [0x0120E7FC+1107964]\n\tOrdinal0 [0x011E94B4+955572]\n\tOrdinal0 [0x0120EA14+1108500]\n\tOrdinal0 [0x0121F192+1175954]\n\tOrdinal0 [0x0120E616+1107478]\n\tOrdinal0 [0x011E7F89+950153]\n\tOrdinal0 [0x011E8F56+954198]\n\tGetHandleVerifier [0x01612CB2+3040210]\n\tGetHandleVerifier [0x01602BB4+2974420]\n\tGetHandleVerifier [0x013B6A0A+565546]\n\tGetHandleVerifier [0x013B5680+560544]\n\tOrdinal0 [0x012B9A5C+1808988]\n\tOrdinal0 [0x012BE3A8+1827752]\n\tOrdinal0 [0x012BE495+1827989]\n\tOrdinal0 [0x012C80A4+1867940]\n\tBaseThreadInitThunk [0x75810419+25]\n\tRtlGetAppContainerNamedObjectPath [0x77E974ED+237]\n\tRtlGetAppContainerNamedObjectPath [0x77E974BD+189]\n"
     ]
    }
   ],
   "source": [
    "#locating the search bar\n",
    "search_bar=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_bar.send_keys('sunglasses')\n",
    "\n",
    "\n",
    "#locating the button and clicking it toh search for sunglasses\n",
    "button=driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f7a5df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_url=[]\n",
    "\n",
    "url=driver.find_elements(By.XPATH,\"//nav[@class='yFHi8N']//a\")\n",
    "for i in url:\n",
    "    page_url.append(i.get_attribute('href'))\n",
    "page_url=page_url[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7a29056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list to scraping data into them\n",
    "\n",
    "brand=[]\n",
    "Description=[]\n",
    "Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f609290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list to scraping data into them\n",
    "\n",
    "brand=[]\n",
    "Description=[]\n",
    "Price=[]\n",
    "\n",
    "# scraping all the tags\n",
    "\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    titles_brand=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    for i in titles_brand:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "    titles_Description=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    for i in titles_Description:\n",
    "        Description.append(i.text)\n",
    "        \n",
    "    titles_Price=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in titles_Price:\n",
    "        Price.append(i.text.replace(\"₹\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d2ffda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe for the first 100 sunglasses listings on flipkart.com:\n",
    "\n",
    "flipkart=pd.DataFrame({})\n",
    "flipkart['Brand']=brand[0:100]\n",
    "flipkart['Product Description']=Description[0:100]\n",
    "flipkart['Price']=Price[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "386ed84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Brand, Product Description, Price]\n",
       "Index: []"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flipkart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67a80f8",
   "metadata": {},
   "source": [
    "# question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2857ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a6cfd0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9ccad448",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.flipkart.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "81e158e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e74132c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Stars</th>\n",
       "      <th>Short Review</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>It is better to buy iPhone 11 over iPhone 12 i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>It was amazing experience for me. Honestly i a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>I bought iPhone 11 On March 2021, And I am Wri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Just go for it.\\nThis phone is really amazing....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>This is my first ever iPhone.\\nAnd I truly don...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Stars         Short Review  \\\n",
       "0                5       Simply awesome   \n",
       "1                5     Perfect product!   \n",
       "2                5  Best in the market!   \n",
       "3                5   Highly recommended   \n",
       "4                5    Worth every penny   \n",
       "..             ...                  ...   \n",
       "95               5    Worth every penny   \n",
       "96               5            Excellent   \n",
       "97               5             Terrific   \n",
       "98               5            Excellent   \n",
       "99               5               Super!   \n",
       "\n",
       "                                          Full Review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   What a camera .....just awesome ..you can feel...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  It is better to buy iPhone 11 over iPhone 12 i...  \n",
       "96  It was amazing experience for me. Honestly i a...  \n",
       "97  I bought iPhone 11 On March 2021, And I am Wri...  \n",
       "98  Just go for it.\\nThis phone is really amazing....  \n",
       "99  This is my first ever iPhone.\\nAnd I truly don...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating empty list\n",
    "urls=[]\n",
    "short_review=[]\n",
    "complete_review=[]\n",
    "stars=[]\n",
    "time.sleep(2)\n",
    "\n",
    "#scraping 10 pages url\n",
    "url_1 = driver.find_elements(By.XPATH,\"//a[@class='ge-49M _2Kfbh8']\")\n",
    "for i in url_1:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "url_2 = driver.find_elements(By.XPATH,\"//a[@class='ge-49M']\")\n",
    "for i in url_2:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "time.sleep(4)\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    #for scrapping the number of stars\n",
    "    for j in driver.find_elements(By.XPATH,\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\"):\n",
    "        stars.append(j.text)\n",
    "    #for scrapping the short review\n",
    "    for k in driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\"):\n",
    "        short_review.append(k.text)\n",
    "    #for scrapping the complete review\n",
    "    for l in driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']/div/div\"):\n",
    "        complete_review.append(l.text)\n",
    "        \n",
    "#Combining all the lists into a single dataframe\n",
    "df=pd.DataFrame({'Number of Stars': stars,\n",
    "                'Short Review': short_review,\n",
    "               'Full Review': complete_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1a7494",
   "metadata": {},
   "source": [
    "# question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1817c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9cb0399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e00a8ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.flipkart.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "72d36cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"//div[@class='_3OO5Xc']//input\")\n",
    "search.send_keys('sneakers')\n",
    "\n",
    "apply=driver.find_element(By.XPATH,\"//button[@class='L0Z3Pu']\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "16ae6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]\n",
    "Brand=[]\n",
    "Description=[]\n",
    "Price=[]\n",
    "Discount=[]\n",
    "for i in range(0,3):\n",
    "    for j in driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\"):\n",
    "        urls.append(j.get_attribute('href'))\n",
    "    for i in range(0,3):\n",
    "        for i in driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\"):\n",
    "            Brand.append(i.text)\n",
    "        for i in driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\"):\n",
    "            Description.append(i.text)\n",
    "        for i in driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\"):\n",
    "            Price.append(i.text)\n",
    "        for i in driver.find_elements(By.XPATH,\"//div[@class='_3Ay6Sb']//span\"):\n",
    "            Discount.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6209467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Brand']=Brand[:100]\n",
    "df['Price']=Price[:100]\n",
    "df['Discount']=Discount[:100]\n",
    "df['Description']=Description[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a486fcdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Brand, Price, Discount, Description]\n",
       "Index: []"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b56ea4b",
   "metadata": {},
   "source": [
    "# question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1fc65640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5b5f6a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c5d023e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=' https://www.myntra.com/shoes'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1279b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_fitler=driver.find_element(By.XPATH,'/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div')\n",
    "color_fitler.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8da55ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_filter=driver.find_element(By.XPATH,'/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div')\n",
    "price_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2c3a89bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]\n",
    "Brand=[]\n",
    "Description=[]\n",
    "Price=[]\n",
    "for i in range(0,3):\n",
    "    for j in driver.find_elements(By.XPATH,\"//ul[@class='results-base']//a\"):\n",
    "        urls.append(j.get_attribute('href'))\n",
    "    for i in range(0,3):\n",
    "        for i in driver.find_elements(By.XPATH,\"//h3[@class='product-brand']\"):\n",
    "            Brand.append(i.text)\n",
    "        for i in driver.find_elements(By.XPATH,\"//h4[@class='product-product']\"):\n",
    "            Description.append(i.text)\n",
    "        for i in driver.find_elements(By.XPATH,\"//div[@class='product-price']//span\"):\n",
    "            Price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fd0e6913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 7880Rs. 8295</td>\n",
       "      <td>Men ZOOM WINFLO8 Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Rs. 7880</td>\n",
       "      <td>Men Sports Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Rs. 8295</td>\n",
       "      <td>Men Niteball II Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>(5% OFF)</td>\n",
       "      <td>Men React Infinity 3 Running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Rs. 8499</td>\n",
       "      <td>Men Leather Niteball Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>(10% OFF)</td>\n",
       "      <td>Men Retropy F90 Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Rs. 8799Rs. 10999</td>\n",
       "      <td>Men Leather Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Rs. 8799</td>\n",
       "      <td>Men 4DFWD_Pulse Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Rs. 10999</td>\n",
       "      <td>Men Solid Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>(20% OFF)</td>\n",
       "      <td>Men Leather Sneakers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand              Price                     Description\n",
       "0               Nike   Rs. 7880Rs. 8295  Men ZOOM WINFLO8 Running Shoes\n",
       "1           Skechers           Rs. 7880                Men Sports Shoes\n",
       "2   ADIDAS Originals           Rs. 8295        Men Niteball II Sneakers\n",
       "3               Nike           (5% OFF)    Men React Infinity 3 Running\n",
       "4   ADIDAS Originals           Rs. 8499   Men Leather Niteball Sneakers\n",
       "..               ...                ...                             ...\n",
       "95  ADIDAS Originals          (10% OFF)        Men Retropy F90 Sneakers\n",
       "96    Tommy Hilfiger  Rs. 8799Rs. 10999            Men Leather Sneakers\n",
       "97            ADIDAS           Rs. 8799   Men 4DFWD_Pulse Running Shoes\n",
       "98    Tommy Hilfiger          Rs. 10999              Men Solid Sneakers\n",
       "99    Tommy Hilfiger          (20% OFF)            Men Leather Sneakers\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Brand']=Brand[:100]\n",
    "df['Price']=Price[:100]\n",
    "df['Description']=Description[:100]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3357d2c6",
   "metadata": {},
   "source": [
    "# question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2bd93864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ed109ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "21767900",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5443cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop = driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "laptop.send_keys('laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "593f3015",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search.send_keys('laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "17242d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding search\n",
    "search = driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3745ae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "title = []\n",
    "laptop_rating = []\n",
    "laptop_price = []\n",
    "#title scraping\n",
    "laptop_title = driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in laptop_title[0:10]:\n",
    "    lap_title = i.text\n",
    "    title.append(lap_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4a3d58e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping price\n",
    "lap_price = driver.find_elements(By.XPATH, '//span[@class=\"a-price-whole\"]')\n",
    "for i in lap_price[0:10]:\n",
    "    laptop_price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "14762338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(title),len(laptop_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c0ef67e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping ratings\n",
    "url = driver.find_elements(By.XPATH,\"//a[@class='a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal']\")\n",
    "url1 = []\n",
    "\n",
    "\n",
    "for i in url[:10]:\n",
    "    url1.append(i.get_attribute('href'))\n",
    "for url2 in url1:\n",
    "    driver.get(url2)\n",
    "    try:                  \n",
    "        rating = driver.find_element(By.XPATH, \"//span[@class='a-size-base a-nowrap']//span\")\n",
    "        laptop_rating.append(rating.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        laptop_rating.append(\"NO rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "775f447f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_25b1e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_25b1e_level0_col0\" class=\"col_heading level0 col0\" >Title</th>\n",
       "      <th id=\"T_25b1e_level0_col1\" class=\"col_heading level0 col1\" >Ratings</th>\n",
       "      <th id=\"T_25b1e_level0_col2\" class=\"col_heading level0 col2\" >Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_25b1e_row0_col0\" class=\"data row0 col0\" >Acer Aspire 3 Intel Core i3 11th Generation 15.6-inch (39.6 cms) Full HD Laptop - (8 GB/256 GB SSD/Windows 11 Home/Intel UHD Graphics /1.7 Kg/Silver) A315-58</td>\n",
       "      <td id=\"T_25b1e_row0_col1\" class=\"data row0 col1\" >3.5 out of 5</td>\n",
       "      <td id=\"T_25b1e_row0_col2\" class=\"data row0 col2\" >36,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_25b1e_row1_col0\" class=\"data row1 col0\" >Acer Aspire 3 Laptop (Made in India) A314-35 35.56 cm (14-Inch) HD Display (Intel Celeron Dual -Core Processor N4500 | Windows 11 Home | 8 GB | 256GB SSD | Weight : 1.45 Kg| Silver</td>\n",
       "      <td id=\"T_25b1e_row1_col1\" class=\"data row1 col1\" >3.6 out of 5</td>\n",
       "      <td id=\"T_25b1e_row1_col2\" class=\"data row1 col2\" >26,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_25b1e_row2_col0\" class=\"data row2 col0\" >ASUS VivoBook 15 (2021), 15.6-inch (39.62 cm) HD, Dual Core Intel Celeron N4020, Thin and Light Laptop (4GB RAM/256GB SSD/Integrated Graphics/Windows 11 Home/Transparent Silver/1.8 Kg), X515MA-BR011W</td>\n",
       "      <td id=\"T_25b1e_row2_col1\" class=\"data row2 col1\" >4.1 out of 5</td>\n",
       "      <td id=\"T_25b1e_row2_col2\" class=\"data row2 col2\" >25,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_25b1e_row3_col0\" class=\"data row3 col0\" >(Renewed) HP Stream 11 G4 11.6in LCD Laptop- Intel Celeron N3350 Dual-core (2 Core) 1.10 GHz - 4 GB DDR3L SDRAM - 64 GB Flash Memory Windows 10</td>\n",
       "      <td id=\"T_25b1e_row3_col1\" class=\"data row3 col1\" >NO rating</td>\n",
       "      <td id=\"T_25b1e_row3_col2\" class=\"data row3 col2\" >14,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_25b1e_row4_col0\" class=\"data row4 col0\" >Lenovo IdeaPad Slim 1 Intel Celeron N4020 11.6'' (29.46cm) HD Thin & Light Laptop (4GB/256GB SSD/Windows 11/Office 2021/3months Game Pass/Platinum Grey/1.2Kg), 81VT009UIN</td>\n",
       "      <td id=\"T_25b1e_row4_col1\" class=\"data row4 col1\" >3.9 out of 5</td>\n",
       "      <td id=\"T_25b1e_row4_col2\" class=\"data row4 col2\" >21,513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_25b1e_row5_col0\" class=\"data row5 col0\" >MSI Modern 14, Intel i5-1155G7, 14\"(35cm) FHD IPS-Level 60Hz Panel Laptop (8GB/512GB NVMe SSD/Windows 10 Home/Intel UHD Graphics/Carbon Grey/1.3Kg), B11MOU-861IN</td>\n",
       "      <td id=\"T_25b1e_row5_col1\" class=\"data row5 col1\" >4 out of 5</td>\n",
       "      <td id=\"T_25b1e_row5_col2\" class=\"data row5 col2\" >29,790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_25b1e_row6_col0\" class=\"data row6 col0\" >Lenovo IdeaPad Slim 3 Intel Celeron N4020 15.6\" (39.62cm) HD Thin & Light Laptop (8GB/256GB SSD/Windows 11/Office 2021/2Yr Warranty/3months Game Pass/Platinum Grey/1.7Kg), 81WQ00MQIN</td>\n",
       "      <td id=\"T_25b1e_row6_col1\" class=\"data row6 col1\" >4.4 out of 5</td>\n",
       "      <td id=\"T_25b1e_row6_col2\" class=\"data row6 col2\" >45,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_25b1e_row7_col0\" class=\"data row7 col0\" >Redmi Book 15 Intel Core I3 11Th Gen/8 Gb/256 Gb Ssd/Windows 11 Home/15.6 Inches (39.62 Cms) Fhd Anti Glare/Ms Office/Charcoal Gray/1.8 Kg Thin and Light Laptop</td>\n",
       "      <td id=\"T_25b1e_row7_col1\" class=\"data row7 col1\" >4.1 out of 5</td>\n",
       "      <td id=\"T_25b1e_row7_col2\" class=\"data row7 col2\" >79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_25b1e_row8_col0\" class=\"data row8 col0\" >HP 14s, 5th Gen AMD Ryzen 3- 8GB RAM/512GB SSD 14 inches(35cm) Laptop, FHD IPS Micro-Edge Display/ Backlit Keyboard/Alexa/Windows 11/Fast Charge/Radeon Graphics/1.46Kg/Natural Silver) -14s-fq1089AU</td>\n",
       "      <td id=\"T_25b1e_row8_col1\" class=\"data row8 col1\" >4.1 out of 5</td>\n",
       "      <td id=\"T_25b1e_row8_col2\" class=\"data row8 col2\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_25b1e_row9_col0\" class=\"data row9 col0\" >Lenovo IdeaPad D330 Intel Celeron N4020 10.1\" (25cm)HD IPS Detachable 2-in-1 Laptop (4GB/128GB eMMC/Windows 10/1 Yr Warranty/Mineral Grey/1.1Kg), 82H0001YIN</td>\n",
       "      <td id=\"T_25b1e_row9_col1\" class=\"data row9 col1\" >4.2 out of 5</td>\n",
       "      <td id=\"T_25b1e_row9_col2\" class=\"data row9 col2\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d8f6bdb370>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating dataframe\n",
    "laptop_df = pd.DataFrame({'Title':title, 'Ratings': laptop_rating, 'Price':laptop_price})\n",
    "laptop_df = laptop_df.style.hide_index()\n",
    "laptop_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126f326d",
   "metadata": {},
   "source": [
    "# question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf7074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa46819",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\" https://www.ambitionbox.com//\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b73950",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'/html/body/div/div/div/div[1]/header/nav/ul/li[5]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd75248",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = driver.find_element(By.XPATH, '/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input')\n",
    "data.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e129f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH, '/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button/span').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701e41ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element(By.XPATH, '/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input')\n",
    "location.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e456312",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18770405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "Company = []\n",
    "no_day = []\n",
    "c_rating = []\n",
    "\n",
    "#Scraping first 10 company names.\n",
    "c_name = driver.find_elements(By.XPATH, '//p[@class=\"company body-medium\"]')\n",
    "for i in c_name[0:10]:\n",
    "    Company.append(i.text)\n",
    "    \n",
    "#Scraping No of days ago when job posted\n",
    "days = driver.find_elements(By.XPATH, \"//div[@class='other-info']/span[1]\")\n",
    "for i in days[0:20]:\n",
    "    nos = i.text\n",
    "    no_day.append(nos)\n",
    "    \n",
    "#Scraping rating of the company\n",
    "com_rat = driver.find_elements(By.XPATH, '//span[@class=\"body-small\"]')\n",
    "for i in com_rat[0:10]:\n",
    "    c_rating.append(i.text)\n",
    "    \n",
    "c_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49870d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Daframe to showcase scrapped data\n",
    "job = pd.DataFrame({'Company Name':Company, 'No Of Days Ago Job Posted':no_day, 'Company Rating':c_rating})\n",
    "job = job.style.hide_index()\n",
    "job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac48703",
   "metadata": {},
   "source": [
    "# question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcf212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc4c4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening Ambitionbox page on automated webdriver\n",
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0872a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d045204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on salary\n",
    "time.sleep(3)\n",
    "driver.find_element(By.XPATH, '/html/body/div/div/div/div[1]/header/nav/ul/li[3]/span').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e371f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on Browse salaries \n",
    "driver.find_element(By.XPATH, '/html/body/div/div/div/div[1]/header/nav/ul/li[3]/div/ul/li[1]/div/div[2]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8167b150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter Data Scientist\n",
    "time.sleep(2)\n",
    "ds = driver.find_element(By.XPATH, '/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input')\n",
    "ds.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fccee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on Data Scientist\n",
    "data = driver.find_elements(By.CLASS_NAME, 'tt_text')\n",
    "data[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608b4fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list.\n",
    "ds_com = []\n",
    "no_sal = []\n",
    "avg_sal = []\n",
    "min_sal = []\n",
    "max_sal = []\n",
    "exp_req = []\n",
    "\n",
    "#Scraping company name\n",
    "comp_name = driver.find_elements(By.XPATH, '//div[@class=\"company-info\"]')\n",
    "for i in comp_name:\n",
    "    ds_com.append(i.text.split('\\n')[0])\n",
    "    \n",
    "#Scraping total salary record\n",
    "for i in comp_name:\n",
    "    no_sal.append(i.text.split('\\n')[-1].split('(')[-1].strip(')').strip(' '))\n",
    "\n",
    "#Scraping average salary\n",
    "av = driver.find_elements(By.XPATH, '//p[@class=\"averageCtc\"]')\n",
    "for i in av:\n",
    "    avg_sal.append(i.text.split('₹')[-1])\n",
    "    \n",
    "#Scraping minimum salary\n",
    "mini = driver.find_elements(By.XPATH, '//div[@class=\"salary-values\"]')\n",
    "for i in mini:\n",
    "    min_sal.append(i.text.split('\\n')[0].strip('₹').strip(' '))\n",
    "\n",
    "#Scraping maximum salary\n",
    "for i in mini:\n",
    "    max_sal.append(i.text.split('\\n')[1].strip('₹').strip(' '))\n",
    "    \n",
    "#Scraping experience required\n",
    "for i in comp_name:\n",
    "    exp_req.append(i.text.split('\\n')[-1].split('(')[0].strip(' '))\n",
    "    \n",
    "#creating dataframe\n",
    "DF = pd.DataFrame({'Company Name':ds_com[0:10], 'Total No Of Records':no_sal[0:10], 'Average Salary':avg_sal[0:10], 'Minimun Salary':min_sal[0:10], 'Maximum Salary':max_sal[0:10], 'Experience Required':exp_req[0:10]})\n",
    "DF = DF.style.hide_index()\n",
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6322b908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
